{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7089b9b4-d7fe-4922-aced-795b7b9cdc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Using cached textblob-0.19.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting nltk>=3.9 (from textblob)\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.12/site-packages (from nltk>=3.9->textblob) (8.1.8)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.12/site-packages (from nltk>=3.9->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from nltk>=3.9->textblob) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from nltk>=3.9->textblob) (4.66.4)\n",
      "Using cached textblob-0.19.0-py3-none-any.whl (624 kB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Installing collected packages: nltk, textblob\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.8.1\n",
      "    Uninstalling nltk-3.8.1:\n",
      "      Successfully uninstalled nltk-3.8.1\n",
      "Successfully installed nltk-3.9.1 textblob-0.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a106fcb4-a45d-4cbe-bce1-401962d1e5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Pranav/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Pranav/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected Tokens after cleaning:\n",
      "['hunger', 'games', 'set', 'dystopian', 'world', 'called', 'panel', 'consists', 'capitol', 'twelve', 'districts', 'every', 'year', 'capitol', 'hosts', 'televised', 'event', 'called', 'hunger', 'games', 'one', 'boy', 'one', 'girl', 'district', 'chosen', 'fight', 'death', 'katniss', 'evergreen', 'volunteers', 'place', 'sister', 'prim', 'becomes', 'female', 'tribute', 'district', 'petya', 'cellar', 'male', 'tribute', 'travel', 'capitol', 'train', 'capitol', 'rich', 'technological', 'advanced', 'contrast', 'districts', 'poor', 'oppressed', 'tributes', 'receive', 'training', 'entering', 'arena', 'katniss', 'shows', 'archery', 'skill', 'training', 'impresses', 'homemakers', 'determination', 'arena', 'survival', 'key', 'katniss', 'uses', 'hunting', 'skill', 'survive', 'forms', 'temporary', 'alliance', 'rue', 'rue', 'reminds', 'katniss', 'sister', 'rules', 'death', 'katniss', 'honors', 'act', 'defines', 'capitol', 'sparks', 'hope', 'among', 'districts']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Step 1: Read the text file\n",
    "with open('ai1.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Step 2: Text cleaning (remove punctuation, numbers, extra spaces)\n",
    "text = re.sub(r'[^A-Za-z\\s]', '', text)  # Keep only letters and spaces\n",
    "text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "\n",
    "# Step 3: Convert to lowercase\n",
    "text = text.lower()\n",
    "\n",
    "# Step 4: Tokenization\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Step 5: Remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "# Step 6: Correct misspelled words\n",
    "corrected_tokens = []\n",
    "for word in filtered_tokens:\n",
    "    corrected_word = str(TextBlob(word).correct())\n",
    "    corrected_tokens.append(corrected_word)\n",
    "\n",
    "# Final output\n",
    "print(\"Corrected Tokens after cleaning:\")\n",
    "print(corrected_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd0f66f-3259-4553-b984-63650e7e0e60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
